from pathlib import Path

from kfp.v2.dsl import Dataset, Input, Output, component

from src.components.dependencies import LOGURU, PANDAS, PYTHON, SCIKIT_LEARN


@component(
    base_image=PYTHON,
    packages_to_install=[LOGURU, PANDAS, SCIKIT_LEARN],
    output_component_file=str(Path(__file__).with_suffix(".yaml")),
)
def train_test_split(
    input_dataset: Input[Dataset],
    target_column: str,
    test_size: float,
    output_train_dataset: Output[Dataset],
    output_test_dataset: Output[Dataset],
) -> None:
    """Split a Dataset into training and test set.

    Args:
        input_dataset (Input[Dataset]): Input Dataset in CSV format.
        target_column (str): Name of the column containing the classification
            target, used to keep the right proportions in the results.
        test_size (float): Percentage of data to be included in the test set.
            Must be a number between 0 and 1 (excluded).
        output_train_dataset (Output[Dataset]): Output training Dataset
            generated by this operation, this parameter will be passed
            automatically by the orchestrator.
        output_test_dataset (Output[Dataset]): Output test Dataset
            generated by this operation, this parameter will be passed
            automatically by the orchestrator.
    """
    import pandas as pd
    from loguru import logger
    from sklearn.model_selection import StratifiedShuffleSplit

    df = pd.read_csv(input_dataset.path)

    splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)
    [(train_idx, test_idx)] = [
        i for i in splitter.split(X=pd.DataFrame(index=df.index), y=df[target_column])
    ]

    train_df = df[train_idx].copy()
    test_df = df[test_idx].copy()

    train_df.to_csv(output_train_dataset.path, index=None)
    test_df.to_csv(output_test_dataset.path, index=None)

    logger.info(f"Exported training data to {output_train_dataset.path}.")
    logger.info(f"Exported test data to {output_test_dataset.path}.")
